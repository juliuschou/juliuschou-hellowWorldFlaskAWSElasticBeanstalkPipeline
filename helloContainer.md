# Comprehensive Guide to Building and Deploying a Flask and scikit-learn Application in a Docker Container

The task involves several steps, each requiring some technical skills in areas such as Docker, Flask web framework, and machine learning using scikit-learn. Here is a breakdown of the task:

# 1: Create a Flask Application with scikit-learn Model

1.1.  **Initialize a New Python Project**: 

- Create a python virtual env and a source folder. Create a `requirements.txt` to list the Python packages you'll need (Flask, scikit-learn, etc.).
    
        python -m venv helloContainerWithFlaskAndScikitLearnApp
        
        mkdir helloContainerWithFlaskAndScikitLearnWS && cd helloContainerWithFlaskAndScikitLearnWS
    
        #requirements.txt
        Flask==2.2.5
        joblib==1.3.2
        numpy==1.21.6
        pandas==1.3.5
        python-dateutil==2.8.2
        requests==2.31.0
        scikit-learn==1.0.2        

![image](https://github.com/juliuschou/juliuschou-hellowWorldFlaskAWSElasticBeanstalkPipeline/assets/4725611/a98c7156-77b5-4813-abfd-36e6f20d0c8a)
    
1.2.  **Create a Flask App**: 
- Create a WORKDIRDIR folder named webapp. Create a Python script, like `app.py` in webapp folder, where you import Flask and initialize a Flask web application.

1.3.  **Train scikit-learn Model**: 
- Train a new scikit-learn model. 

    
1.4.  **Load scikit-learn Model**: 
- Within `app.py`, load a pre-trained model. You can use joblib or pickle to load the model.
    
1.5.  **Predictive Endpoint**: 
- Create a Flask route (e.g., `/predict`) that uses the trained scikit-learn model to make predictions based on input data.
    
1.6.  **Example Endpoint**: 
- Create another Flask route (e.g., `/example`) that returns an example GET request to interact with the model.
    
1.7.  **Metadata Endpoint**: 
- Create yet another Flask route (e.g., `/metadata`) that returns metadata about the model like algorithm used, feature importance, etc.
    

# 2: Containerize the Flask Application with Docker

2.1.  **Install Docker**: If you haven't already, install Docker on your machine.
	
- **Step 1.** Update Software Repositories
		
    It's a good idea to make sure your local software repositories are up to date.
				
        sudo apt update 

- **Step 2.** Install Dependencies
	
    Install some essential packages that are necessary for Docker and its components.
    		
        sudo apt install apt-transport-https ca-certificates curl software-properties-common
    		 
		
- **Step 3.** Add Dockerâ€™s GPG Key

    Next, you can add Docker's GPG key for a secure installation.
  		
        curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
  		 

- **Step 4.** Add Docker Repository
		
    Now, add the Docker repository to your system.

        sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"
		 

- **Step 5.** Update Software Repositories Again
    
    Run the apt update command again to refresh your local database with the Docker packages.
			
        sudo apt update
		 

- **Step 6.** Install Docker
    
    Now, you can install Docker.
				
        sudo apt install docker-ce
		 

- **Step 7.** Enable and Start Docker
        
    Finally, enable and start the Docker service.
				
        sudo systemctl enable docker
        sudo systemctl start docker
    		 

- **Step 8.** Verify Installation
    
    To verify that Docker was installed correctly, you can run the following command which will download a test image and run a container from it.
		
        sudo docker run hello-world
		 
    If you see a message that says something along the lines of "Hello from Docker!", your installation has been successful.    

2.2.  **Create a `Dockerfile`**: In the root of your project, create a `Dockerfile` that starts with a base Python image and copies your project files into the container.
    
2.3.  **Build Docker Image**: Run `docker build` to create a Docker image of your application.
    
2.4.  **Run Docker Container**: Run a container from the built image and map the necessary ports.
    
2.5.  **Test the Container**: Send requests to the containerized application to make sure everything is working as expected.
    

## Code snippets for illustration:

### app.py


    from flask import Flask, request, jsonify
    
    import json
    import joblib
    from sklearn.preprocessing import StandardScaler
    import numpy as np
    
    app = Flask(__name__)
    
    def scale(payload):
        scaler = StandardScaler().fit(payload)
        return scaler.transform(payload)
    
    @app.route("/")
    def home():
        return "<h3>Sklearn Prediction Container</h3>"
    
    @app.route("/predict", methods=['POST'])
    def predict():
        """
            Input sample:
        		{
        		  "MedInc": 3.2596,
        		  "HouseAge": 33,
        		  "AveRooms": 5.017657,
        		  "AveBedrms": 1.006421,
        		  "Population": 2300,
        		  "AveOccup": 3.691814,
        		  "Latitude": 32.71,
        		  "Longitude": -117.03
        		}
    
            Output sample:
                {"prediction" : [1.9372587405453814]}
        """
        try:
            loaded_model = joblib.load("california_housing_prediction.joblib")
    
            # Since you're expecting JSON, you can use request.json directly
            data_dict = request.json
    
            values_list = list(data_dict.values())
            sample_data_point = np.array([values_list])
    
            predicted_value = loaded_model.predict(sample_data_point)
    
            # Convert the NumPy array to a Python list
            return jsonify({'prediction': predicted_value.tolist()})
    
        except Exception as e:
            return jsonify({'error': str(e)})
    
    @app.route("/metadata", methods=["GET"])
    def metadata():
        try:
            # Load the trained model from the file
            loaded_model = joblib.load("california_housing_prediction.joblib")
        except Exception as e:
            return jsonify({"error": str(e)})
    
        # Extract model metadata
        coef = loaded_model.coef_
        intercept = loaded_model.intercept_
    
        feature_names = ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']
    
        feature_coef_map = {}
        for feature, coef_value in zip(feature_names, coef):
            feature_coef_map[feature] = coef_value
    
        return jsonify({
            "model_coefficients": feature_coef_map,
            "model_intercept": intercept,
        })
    
    if __name__ == "__main__":
        app.run(host='0.0.0.0', port=5000, debug=True)

### Tran and dump a new train a new scikit-learn model
		
    from sklearn.model_selection import train_test_split
    from sklearn.linear_model import LinearRegression
    import joblib
    
    from sklearn.datasets import fetch_california_housing
    
    # Load the california Housing dataset
    california = fetch_california_housing()
    X = california.data
    y = california.target
    
    # Split the data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # Initialize and train the model
    model = LinearRegression()
    model.fit(X_train, y_train)
    
    # Save the trained model
    joblib.dump(model, "california_housing_prediction.joblib")


### `Dockerfile`


    FROM python:3.7
    
    ARG VERSION
    
    LABEL org.label-schema.version=$VERSION
    
    COPY ./california_housing_prediction.joblib /webapp/california_housing_prediction.joblib
    
    COPY ./requirements.txt /webapp/requirements.txt
    
    WORKDIR /webapp
    
    RUN pip install -r requirements.txt
    
    COPY webapp/* /webapp
    
    ENTRYPOINT ["python"]
    
    CMD ["app.py"]


### Commands to build and run Docker container

    # Build the container image
    docker build --build-arg VERSION=Auto_287f444c -t flask-predict .
    
    #Double-check that the image is now available after building
    docker images flask-predict
    
    # Run the container in the background
    docker run -p 5000:5000 -d --name flask-predict flask-predict  

# 3: Test and Deploy

3.1.  **Test the Application**: Make sure to test your Flask routes thoroughly.
    
3.2.  **Deploy the Container**: Optionally, you can deploy the Docker container to a cloud service for more extensive testing or production usage.
    

That should cover most of the steps involved in fulfilling your task.
